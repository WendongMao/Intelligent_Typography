------------ Options -------------
N_CRITIC: 5
batchSize: 1
beta1: 0.5
checkpoints_dir: ./checkpoints
continue_train: False
dataroot: ./datasets/half/202
dataset_mode: half_crop
display_freq: 500
display_id: 1
display_port: 8097
display_single_pane_ncols: 0
display_winsize: 256
epoch_count: 1
fineSize: 256
gpu_ids: [3]
gradient_penalty: False
identity: 0.0
input_nc: 3
isTrain: True
lambda_A: 100.0
lambda_B: 10.0
loadSize: 286
lr: 0.0002
max_dataset_size: inf
model: half_style
nThreads: 2
n_layers_D: 4
name: model_change
ndf: 64
ngf: 64
niter: 50000
niter_decay: 50000
no_dropout: False
no_flip: True
no_html: False
no_lsgan: True
norm: batch
output_nc: 3
padding_type: replicate
phase: train
pool_size: 0
print_freq: 20
resize_or_crop: no
save_epoch_freq: 1000
save_latest_freq: 2000
serial_batches: False
use_style: True
which_direction: AtoB
which_epoch: latest
which_model_netD: n_layers
which_model_netG: resnet_2x_6blocks
-------------- End ----------------
CustomDatasetDataLoader
dataset [HalfDataset] was created
Traceback (most recent call last):
  File "/home/shihonghong/text_nonsyn2/train.py", line 12, in <module>
    data_loader = CreateDataLoader(opt)
  File "/home/shihonghong/text_nonsyn2/data/data_loader.py", line 6, in CreateDataLoader
    data_loader.initialize(opt)
  File "/home/shihonghong/text_nonsyn2/data/custom_dataset_data_loader.py", line 33, in initialize
    self.dataset = CreateDataset(opt)
  File "/home/shihonghong/text_nonsyn2/data/custom_dataset_data_loader.py", line 23, in CreateDataset
    dataset.initialize(opt)
  File "/home/shihonghong/text_nonsyn2/data/half_dataset.py", line 19, in initialize
    self.paths = make_dataset(self.dir)
  File "/home/shihonghong/text_nonsyn2/data/image_folder.py", line 26, in make_dataset
    assert os.path.isdir(dir), '%s is not a valid directory' % dir
AssertionError: ./datasets/half/202/train is not a valid directory
------------ Options -------------
N_CRITIC: 5
batchSize: 1
beta1: 0.5
checkpoints_dir: ./checkpoints
continue_train: False
dataroot: /home/shihonghong/text_nonsyn2/datasets/half/202
dataset_mode: half_crop
display_freq: 500
display_id: 1
display_port: 8097
display_single_pane_ncols: 0
display_winsize: 256
epoch_count: 1
fineSize: 256
gpu_ids: [3]
gradient_penalty: False
identity: 0.0
input_nc: 3
isTrain: True
lambda_A: 100.0
lambda_B: 10.0
loadSize: 286
lr: 0.0002
max_dataset_size: inf
model: half_style
nThreads: 2
n_layers_D: 4
name: model_change
ndf: 64
ngf: 64
niter: 50000
niter_decay: 50000
no_dropout: False
no_flip: True
no_html: False
no_lsgan: True
norm: batch
output_nc: 3
padding_type: replicate
phase: train
pool_size: 0
print_freq: 20
resize_or_crop: no
save_epoch_freq: 1000
save_latest_freq: 2000
serial_batches: False
use_style: True
which_direction: AtoB
which_epoch: latest
which_model_netD: n_layers
which_model_netG: resnet_2x_6blocks
-------------- End ----------------
CustomDatasetDataLoader
dataset [HalfDataset] was created
#training images = 3
half_style
Traceback (most recent call last):
  File "/home/shihonghong/text_nonsyn2/train.py", line 17, in <module>
    model = create_model(opt)
  File "/home/shihonghong/text_nonsyn2/models/models.py", line 23, in create_model
    model.initialize(opt)
  File "/home/shihonghong/text_nonsyn2/models/half_gan_style.py", line 35, in initialize
    self.vgg.load_state_dict(torch.load(os.getcwd() + '/Models/' + 'vgg_conv.pth'))
  File "/home/shihonghong/anaconda3/envs/torch-cuda/lib/python3.6/site-packages/torch/serialization.py", line 525, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/shihonghong/anaconda3/envs/torch-cuda/lib/python3.6/site-packages/torch/serialization.py", line 212, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/shihonghong/anaconda3/envs/torch-cuda/lib/python3.6/site-packages/torch/serialization.py", line 193, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/shihonghong/text_nonsyn2/scripts/Models/vgg_conv.pth'
